#!/usr/bin/env python3
"""
æ¶æ„åˆ†æå™¨ - åˆ†æé¡¹ç›®æ¶æ„é£é™©å’Œé‡å¤ä»£ç 
ç”¨äºsystem-chainæŠ€èƒ½çš„æ¶æ„åˆ†æåŠŸèƒ½
"""

import os
import ast
import re
from pathlib import Path
from typing import Dict, List, Any, Set, Tuple
from collections import defaultdict

class ArchitectureAnalyzer:
    def __init__(self, root_path: str = "."):
        self.root_path = Path(root_path).resolve()
        self.analysis_results = {
            "duplicate_files": [],
            "duplicate_functions": [],
            "inconsistent_implementations": [],
            "architecture_risks": [],
            "suggestions": []
        }

    def analyze_module(self, module_path: str, project_structure: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææŒ‡å®šæ¨¡å—çš„æ¶æ„é£é™©"""
        print(f"åˆ†ææ¨¡å—: {module_path}")

        module_info = project_structure["modules"].get(module_path, {})
        module_full_path = self.root_path / module_path

        # åˆ†ææ–‡ä»¶é‡å¤
        self._analyze_file_duplicates(module_full_path, module_path)

        # åˆ†æä»£ç é‡å¤
        self._analyze_code_duplicates(module_full_path, module_path)

        # åˆ†æå®ç°ä¸€è‡´æ€§
        self._analyze_implementation_consistency(module_full_path, module_path)

        # ç”Ÿæˆæ¶æ„é£é™©å»ºè®®
        self._generate_architecture_suggestions(module_path, project_structure)

        return self.analysis_results

    def _analyze_file_duplicates(self, module_path: Path, module_name: str):
        """åˆ†ææ–‡ä»¶é‡å¤"""
        files_by_extension = defaultdict(list)

        for file_path in module_path.rglob("*"):
            if file_path.is_file() and not file_path.name.startswith('.'):
                ext = file_path.suffix.lower()
                files_by_extension[ext].append(file_path)

        # æ£€æŸ¥åŒåæ–‡ä»¶
        for ext, files in files_by_extension.items():
            name_groups = defaultdict(list)
            for file_path in files:
                base_name = file_path.stem.lower()
                name_groups[base_name].append(file_path)

            for base_name, duplicate_files in name_groups.items():
                if len(duplicate_files) > 1:
                    self.analysis_results["duplicate_files"].append({
                        "module": module_name,
                        "files": [str(f.relative_to(self.root_path)) for f in duplicate_files],
                        "issue": f"å‘ç°åŒåæ–‡ä»¶é‡å¤: {base_name}{ext}"
                    })

    def _analyze_code_duplicates(self, module_path: Path, module_name: str):
        """åˆ†æä»£ç é‡å¤ï¼ˆPythonæ–‡ä»¶ï¼‰"""
        python_files = list(module_path.glob("*.py"))
        function_signatures = defaultdict(list)

        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # è§£æASTæå–å‡½æ•°
                try:
                    tree = ast.parse(content)
                    for node in ast.walk(tree):
                        if isinstance(node, ast.FunctionDef):
                            func_name = node.name
                            # æå–å‡½æ•°ç­¾åï¼ˆå‚æ•°æ•°é‡ï¼‰
                            arg_count = len(node.args.args)
                            signature = f"{func_name}({arg_count} args)"

                            function_signatures[signature].append({
                                "file": str(py_file.relative_to(self.root_path)),
                                "line": node.lineno,
                                "function": func_name
                            })
                except SyntaxError:
                    continue

            except Exception as e:
                print(f"è§£ææ–‡ä»¶å¤±è´¥ {py_file}: {e}")

        # æ£€æŸ¥é‡å¤å‡½æ•°
        for signature, functions in function_signatures.items():
            if len(functions) > 1:
                self.analysis_results["duplicate_functions"].append({
                    "module": module_name,
                    "signature": signature,
                    "functions": functions,
                    "issue": f"å‘ç°é‡å¤å‡½æ•°ç­¾å: {signature}"
                })

    def _analyze_implementation_consistency(self, module_path: Path, module_name: str):
        """åˆ†æå®ç°ä¸€è‡´æ€§"""
        # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸€è‡´æ€§
        config_files = list(module_path.glob("*.json")) + list(module_path.glob("*.yaml")) + list(module_path.glob("*.yml"))

        if len(config_files) > 1:
            # æ£€æŸ¥é…ç½®ç»“æ„ä¸€è‡´æ€§
            config_structures = []
            for config_file in config_files:
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        if config_file.suffix == '.json':
                            import json
                            config = json.load(f)
                        else:
                            import yaml
                            config = yaml.safe_load(f)

                        # æå–é…ç½®é”®ç»“æ„
                        keys = self._extract_dict_keys(config)
                        config_structures.append({
                            "file": str(config_file.relative_to(self.root_path)),
                            "keys": keys
                        })
                except Exception as e:
                    print(f"è§£æé…ç½®æ–‡ä»¶å¤±è´¥ {config_file}: {e}")

            # æ¯”è¾ƒé…ç½®ç»“æ„å·®å¼‚
            if len(config_structures) > 1:
                for i in range(len(config_structures)):
                    for j in range(i + 1, len(config_structures)):
                        diff = self._compare_key_structures(
                            config_structures[i]["keys"],
                            config_structures[j]["keys"]
                        )
                        if diff:
                            self.analysis_results["inconsistent_implementations"].append({
                                "module": module_name,
                                "files": [
                                    config_structures[i]["file"],
                                    config_structures[j]["file"]
                                ],
                                "issue": f"é…ç½®ç»“æ„ä¸ä¸€è‡´: {diff}"
                            })

    def _generate_architecture_suggestions(self, module_path: str, project_structure: Dict[str, Any]):
        """ç”Ÿæˆæ¶æ„å»ºè®®"""
        suggestions = []

        # æ£€æŸ¥æ¨¡å—å¤æ‚åº¦
        module_info = project_structure["modules"].get(module_path, {})
        file_count = len(module_info.get("files", []))

        if file_count > 20:
            suggestions.append({
                "type": "complexity",
                "message": f"æ¨¡å— {module_path} åŒ…å« {file_count} ä¸ªæ–‡ä»¶ï¼Œå»ºè®®æ‹†åˆ†ä¸ºå­æ¨¡å—",
                "priority": "medium"
            })

        # æ£€æŸ¥readmeå®Œæ•´æ€§
        readme_content = project_structure["readme_files"].get(module_path, "")
        if len(readme_content) < 100:
            suggestions.append({
                "type": "documentation",
                "message": f"æ¨¡å— {module_path} çš„readmeæ–‡æ¡£è¿‡äºç®€å•ï¼Œå»ºè®®å®Œå–„åŠŸèƒ½æè¿°",
                "priority": "high"
            })

        # æ£€æŸ¥æ–‡ä»¶ç»„ç»‡
        if module_info:
            has_subdirs = len(module_info.get("subdirectories", [])) > 0
            if file_count > 10 and not has_subdirs:
                suggestions.append({
                    "type": "organization",
                    "message": f"æ¨¡å— {module_path} æ–‡ä»¶è¾ƒå¤šä½†æ— å­ç›®å½•ï¼Œå»ºè®®æŒ‰åŠŸèƒ½åˆ†ç±»ç»„ç»‡",
                    "priority": "low"
                })

        self.analysis_results["suggestions"].extend(suggestions)

    def _extract_dict_keys(self, d: Dict, prefix: str = "") -> List[str]:
        """é€’å½’æå–å­—å…¸é”®ç»“æ„"""
        keys = []
        for key, value in d.items():
            full_key = f"{prefix}.{key}" if prefix else key
            keys.append(full_key)
            if isinstance(value, dict):
                keys.extend(self._extract_dict_keys(value, full_key))
        return sorted(keys)

    def _compare_key_structures(self, keys1: List[str], keys2: List[str]) -> str:
        """æ¯”è¾ƒä¸¤ä¸ªé”®ç»“æ„çš„å·®å¼‚"""
        set1, set2 = set(keys1), set(keys2)

        only_in_1 = set1 - set2
        only_in_2 = set2 - set1

        differences = []
        if only_in_1:
            differences.append(f"ä»…åœ¨ç¬¬ä¸€ä¸ªé…ç½®ä¸­: {sorted(only_in_1)}")
        if only_in_2:
            differences.append(f"ä»…åœ¨ç¬¬äºŒä¸ªé…ç½®ä¸­: {sorted(only_in_2)}")

        return "; ".join(differences) if differences else ""

    def generate_report(self, output_file: str = None) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Šåˆ°.claude/skill/sysmem/ç›®å½•"""
        if not output_file:
            output_file = "architecture_analysis_report.md"

        # åˆ›å»º.claude/skill/sysmem/ç›®å½•
        claude_skill_dir = self.root_path / ".claude" / "skill" / "sysmem"
        claude_skill_dir.mkdir(parents=True, exist_ok=True)

        output_path = claude_skill_dir / output_file

        report_lines = [
            "# æ¶æ„åˆ†ææŠ¥å‘Š\n",
            f"åˆ†ææ—¶é—´: {self._get_current_time()}",
            f"é¡¹ç›®è·¯å¾„: {self.root_path}\n",
            "## åˆ†æç»“æœ\n"
        ]

        # é‡å¤æ–‡ä»¶
        if self.analysis_results["duplicate_files"]:
            report_lines.append("### ğŸš¨ é‡å¤æ–‡ä»¶\n")
            for item in self.analysis_results["duplicate_files"]:
                report_lines.append(f"**æ¨¡å—**: {item['module']}")
                report_lines.append(f"**é—®é¢˜**: {item['issue']}")
                report_lines.append(f"**æ–‡ä»¶**: {', '.join(item['files'])}\n")

        # é‡å¤å‡½æ•°
        if self.analysis_results["duplicate_functions"]:
            report_lines.append("### ğŸš¨ é‡å¤å‡½æ•°\n")
            for item in self.analysis_results["duplicate_functions"]:
                report_lines.append(f"**æ¨¡å—**: {item['module']}")
                report_lines.append(f"**ç­¾å**: {item['signature']}")
                report_lines.append("**ä½ç½®**:")
                for func in item['functions']:
                    report_lines.append(f"  - {func['file']}:{func['line']}")
                report_lines.append("")

        # å®ç°ä¸ä¸€è‡´
        if self.analysis_results["inconsistent_implementations"]:
            report_lines.append("### âš ï¸ å®ç°ä¸ä¸€è‡´\n")
            for item in self.analysis_results["inconsistent_implementations"]:
                report_lines.append(f"**æ¨¡å—**: {item['module']}")
                report_lines.append(f"**é—®é¢˜**: {item['issue']}")
                report_lines.append(f"**æ–‡ä»¶**: {', '.join(item['files'])}\n")

        # æ¶æ„å»ºè®®
        if self.analysis_results["suggestions"]:
            report_lines.append("### ğŸ’¡ æ¶æ„å»ºè®®\n")
            # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
            by_priority = defaultdict(list)
            for suggestion in self.analysis_results["suggestions"]:
                by_priority[suggestion["priority"]].append(suggestion)

            for priority in ["high", "medium", "low"]:
                if by_priority[priority]:
                    priority_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
                    report_lines.append(f"#### {priority_emoji[priority]} {priority.upper()} ä¼˜å…ˆçº§\n")
                    for suggestion in by_priority[priority]:
                        report_lines.append(f"- {suggestion['message']}")
                    report_lines.append("")

        # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

        return str(output_path)

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

if __name__ == "__main__":
    import sys
    import json

    # ç¡®å®šç›®æ ‡ç›®å½•ï¼šå¦‚æœæä¾›äº†å‚æ•°å°±ä½¿ç”¨å‚æ•°ç›®å½•ï¼Œå¦åˆ™ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
    target_directory = sys.argv[1] if len(sys.argv) > 1 else os.getcwd()

    print(f"ğŸ¯ ç›®æ ‡é¡¹ç›®ç›®å½•: {target_directory}")
    print(f"ğŸ“ è„šæœ¬æ‰§è¡Œç›®å½•: {os.getcwd()}")

    # æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(target_directory):
        print(f"âŒ é”™è¯¯: ç›®æ ‡ç›®å½• '{target_directory}' ä¸å­˜åœ¨")
        sys.exit(1)

    # æŸ¥æ‰¾é¡¹ç›®ç»“æ„æ–‡ä»¶
    structure_file_path = Path(target_directory) / ".claude" / "skill" / "sysmem" / "project_structure.json"

    try:
        with open(structure_file_path, 'r', encoding='utf-8') as f:
            project_structure = json.load(f)
    except FileNotFoundError:
        print(f"âŒ è¯·å…ˆåœ¨ç›®æ ‡ç›®å½•ä¸­è¿è¡Œ scan_project.py ç”Ÿæˆé¡¹ç›®ç»“æ„æ–‡ä»¶")
        print(f"   æœŸæœ›æ–‡ä»¶ä½ç½®: {structure_file_path}")
        sys.exit(1)

    analyzer = ArchitectureAnalyzer(target_directory)

    # åˆ†ææ‰€æœ‰æ¨¡å—
    for module_path in project_structure["modules"].keys():
        results = analyzer.analyze_module(module_path, project_structure)

    # ç”ŸæˆæŠ¥å‘Šåˆ°.claude/skill/sysmem/ç›®å½•
    report_file = analyzer.generate_report()
    print(f"æ¶æ„åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    print(f"âœ… åˆ†ææŠ¥å‘Šå·²åˆ›å»ºåœ¨ç›®æ ‡é¡¹ç›®çš„ .claude/skill/sysmem/ ç›®å½•ä¸­")